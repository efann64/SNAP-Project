{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "random_state = 42\n",
    "import autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,recall_score,precision_score\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier,BaggingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\efann\\Desktop\\SNAP\\final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3904 entries, 0 to 3903\n",
      "Data columns (total 33 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   FSSLTDED  3904 non-null   float64\n",
      " 1   SHELDED   3904 non-null   float64\n",
      " 2   CERTHHSZ  3904 non-null   float64\n",
      " 3   TANF_IND  3904 non-null   float64\n",
      " 4   FSNELDER  3904 non-null   float64\n",
      " 5   FSUNEARN  3904 non-null   float64\n",
      " 6   FSASSET   3904 non-null   float64\n",
      " 7   RAWNET    3904 non-null   float64\n",
      " 8   FSUSIZE   3904 non-null   float64\n",
      " 9   FSNETINC  3904 non-null   float64\n",
      " 10  LIQRESOR  3904 non-null   float64\n",
      " 11  FSSTDDE2  3904 non-null   float64\n",
      " 12  FSSSI     3904 non-null   float64\n",
      " 13  TPOV      3904 non-null   float64\n",
      " 14  HWGT      3904 non-null   float64\n",
      " 15  WRK_POOR  3904 non-null   float64\n",
      " 16  FSTOTDE2  3904 non-null   float64\n",
      " 17  FSDIS     3904 non-null   float64\n",
      " 18  FSGRINC   3904 non-null   float64\n",
      " 19  FSERNDE2  3904 non-null   float64\n",
      " 20  FSEARN    3904 non-null   float64\n",
      " 21  RAWERND   3904 non-null   float64\n",
      " 22  FSGA      3904 non-null   float64\n",
      " 23  FSTANF    3904 non-null   float64\n",
      " 24  FSWAGES   3904 non-null   float64\n",
      " 25  FSNONCIT  3904 non-null   float64\n",
      " 26  FSTOTDED  3904 non-null   float64\n",
      " 27  REALPROP  3904 non-null   float64\n",
      " 28  FSSLTDE2  3904 non-null   float64\n",
      " 29  FSERNDED  3904 non-null   float64\n",
      " 30  CAT_ELIG  3904 non-null   float64\n",
      " 31  FSVEHAST  3904 non-null   float64\n",
      " 32  VEHICLEA  3904 non-null   float64\n",
      "dtypes: float64(33)\n",
      "memory usage: 1006.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upper case X; all columns except for cat elig- that one is the one we are predicting- the y.\n",
    "X = df.drop(columns = ['CAT_ELIG'])\n",
    "y = df['CAT_ELIG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.662398\n",
       "0.0    0.337602\n",
       "Name: CAT_ELIG, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline, NULL Model; this is a starting point and tells you that your model for predicting y, cat_elig, needs to be higher than .66\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the standard test size is anywhere from .2 to .3 meaning 20 to 30 percent for training, you want most of the data to go to training.  If you get a bad accuracy score, this is a place you can change to see if you can make it better\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.3,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(r'C:\\Users\\efann\\Desktop\\SNAP\\TrainTest\\X_train.csv',X_train,delimiter=',')\n",
    "np.savetxt(r'C:\\Users\\efann\\Desktop\\SNAP\\TrainTest\\y_train.csv',y_train,delimiter=',')\n",
    "np.savetxt(r'C:\\Users\\efann\\Desktop\\SNAP\\TrainTest\\X_test.csv',X_test,delimiter=',')\n",
    "np.savetxt(r'C:\\Users\\efann\\Desktop\\SNAP\\TrainTest\\y_test.csv',y_test,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added this I think i missed it before for bagging\n",
    "pca = PCA(n_components=10,random_state=42)\n",
    "pca.fit(X_train)\n",
    "X_train_pc = pca.transform(X_train)\n",
    "X_test_pc = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the first three are white box models; the can be interpreted; the others are boosters\n",
    "models = {\n",
    "    'LogReg': LogisticRegression(),\n",
    "    'Decision Tree':DecisionTreeClassifier(),\n",
    "    'Random Forest':RandomForestClassifier(),\n",
    "    'Gradient Boost':GradientBoostingClassifier(),\n",
    "    'Ada Boost':AdaBoostClassifier(),\n",
    "    'SVC':SVC(),\n",
    "    'Naive Bayes':GaussianNB()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from Dan Brown lecture\n",
    "final = pd.DataFrame(columns = ['cross_val_train','cross_val_test','test_recall','test_precision'])\n",
    "idx=0\n",
    "while idx < len(models.keys()):\n",
    "    for name,model in models.items():\n",
    "        results = {}\n",
    "        results['name']=name\n",
    "        name=model.fit(X_train, y_train)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        results['cross_val_train'] = np.mean(cross_val_score(model,X_train,y_train,cv=4))\n",
    "        results['cross_val_test'] = np.mean(cross_val_score(model,X_test,y_test,cv=4))\n",
    "        results['test_recall'] = recall_score(y_test, y_pred_test)\n",
    "        results['test_precision'] = precision_score(y_test, y_pred_test)\n",
    "        final = final.append(results,ignore_index=True)\n",
    "        idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cross_val_train</th>\n",
       "      <th>cross_val_test</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.884334</td>\n",
       "      <td>0.862628</td>\n",
       "      <td>0.900262</td>\n",
       "      <td>0.903821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.906296</td>\n",
       "      <td>0.912969</td>\n",
       "      <td>0.940945</td>\n",
       "      <td>0.932380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.943265</td>\n",
       "      <td>0.936007</td>\n",
       "      <td>0.959318</td>\n",
       "      <td>0.958060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost</th>\n",
       "      <td>0.941435</td>\n",
       "      <td>0.933447</td>\n",
       "      <td>0.950131</td>\n",
       "      <td>0.961487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost</th>\n",
       "      <td>0.922401</td>\n",
       "      <td>0.920648</td>\n",
       "      <td>0.937008</td>\n",
       "      <td>0.939474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.884700</td>\n",
       "      <td>0.854949</td>\n",
       "      <td>0.901575</td>\n",
       "      <td>0.928378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.767204</td>\n",
       "      <td>0.741468</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.908441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cross_val_train  cross_val_test  test_recall  test_precision\n",
       "name                                                                        \n",
       "LogReg                 0.884334        0.862628     0.900262        0.903821\n",
       "Decision Tree          0.906296        0.912969     0.940945        0.932380\n",
       "Random Forest          0.943265        0.936007     0.959318        0.958060\n",
       "Gradient Boost         0.941435        0.933447     0.950131        0.961487\n",
       "Ada Boost              0.922401        0.920648     0.937008        0.939474\n",
       "SVC                    0.884700        0.854949     0.901575        0.928378\n",
       "Naive Bayes            0.767204        0.741468     0.833333        0.908441"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82       410\n",
      "         1.0       0.90      0.90      0.90       762\n",
      "\n",
      "    accuracy                           0.87      1172\n",
      "   macro avg       0.86      0.86      0.86      1172\n",
      "weighted avg       0.87      0.87      0.87      1172\n",
      "\n",
      "\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.90      0.89       410\n",
      "         1.0       0.95      0.94      0.94       762\n",
      "\n",
      "    accuracy                           0.93      1172\n",
      "   macro avg       0.92      0.92      0.92      1172\n",
      "weighted avg       0.93      0.93      0.93      1172\n",
      "\n",
      "\n",
      "\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.91      0.92       410\n",
      "         1.0       0.95      0.96      0.96       762\n",
      "\n",
      "    accuracy                           0.95      1172\n",
      "   macro avg       0.94      0.94      0.94      1172\n",
      "weighted avg       0.95      0.95      0.95      1172\n",
      "\n",
      "\n",
      "\n",
      "GradientBoostingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.93      0.92       410\n",
      "         1.0       0.96      0.95      0.96       762\n",
      "\n",
      "    accuracy                           0.94      1172\n",
      "   macro avg       0.93      0.94      0.94      1172\n",
      "weighted avg       0.94      0.94      0.94      1172\n",
      "\n",
      "\n",
      "\n",
      "AdaBoostClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.89      0.89       410\n",
      "         1.0       0.94      0.94      0.94       762\n",
      "\n",
      "    accuracy                           0.92      1172\n",
      "   macro avg       0.91      0.91      0.91      1172\n",
      "weighted avg       0.92      0.92      0.92      1172\n",
      "\n",
      "\n",
      "\n",
      "SVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.87      0.85       410\n",
      "         1.0       0.93      0.90      0.91       762\n",
      "\n",
      "    accuracy                           0.89      1172\n",
      "   macro avg       0.88      0.89      0.88      1172\n",
      "weighted avg       0.89      0.89      0.89      1172\n",
      "\n",
      "\n",
      "\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.84      0.78       410\n",
      "         1.0       0.91      0.83      0.87       762\n",
      "\n",
      "    accuracy                           0.84      1172\n",
      "   macro avg       0.82      0.84      0.83      1172\n",
      "weighted avg       0.85      0.84      0.84      1172\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name,model in models.items():\n",
    "    name = model.fit(X_train,y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    print(name)\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8425979870221187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'max_features': None, 'max_leaf_nodes': 10}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing the random tree\n",
    "et = ExtraTreeClassifier()\n",
    "params={'max_depth':[None,3,4],\n",
    "       'max_features':[None,'auto'],\n",
    "       'max_leaf_nodes':[5,10]}\n",
    "et_gs = GridSearchCV(et,param_grid=params)\n",
    "et_gs.fit(X_train,y_train)\n",
    "print(et_gs.best_score_)\n",
    "et_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_train = 0.7269399707174231\n",
      "cross_val_test = 0.7133105802047782\n",
      "test_recall = 0.9501312335958005\n",
      "test_precision = 0.9476439790575916\n"
     ]
    }
   ],
   "source": [
    "#Testing bagging, code didn't work X_train_pc not defined at first but added the missing code\n",
    "bag = BaggingClassifier()\n",
    "bag.fit(X_train,y_train)\n",
    "y_pred_train = bag.predict(X_train)\n",
    "y_pred_test = bag.predict(X_test)\n",
    "print(f'cross_val_train = {np.mean(cross_val_score(model,X_train_pc,y_train,cv=4))}')\n",
    "print(f'cross_val_test = {np.mean(cross_val_score(model,X_test_pc,y_test,cv=4))}')\n",
    "print(f'test_recall = {recall_score(y_test, y_pred_test)}')\n",
    "print(f'test_precision = {precision_score(y_test, y_pred_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9439962231552727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'max_features': 'auto', 'n_estimators': 125}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "params={'max_depth':[None,3,4],\n",
    "       'max_features':[None,'auto'],\n",
    "       'n_estimators':[75,100,125]}\n",
    "rf_gs = GridSearchCV(rf,param_grid=params)\n",
    "rf_gs.fit(X_train,y_train)\n",
    "print(rf_gs.best_score_)\n",
    "rf_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote = VotingClassifier([\n",
    "    ('rf',RandomForestClassifier(bootstrap=False,n_estimators=1000)),\n",
    "    ('gb',GradientBoostingClassifier(max_depth=10,subsample=0.8)),\n",
    "    ('bag',BaggingClassifier(n_estimators = 10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              RandomForestClassifier(bootstrap=False,\n",
       "                                                     n_estimators=1000)),\n",
       "                             ('gb',\n",
       "                              GradientBoostingClassifier(max_depth=10,\n",
       "                                                         subsample=0.8)),\n",
       "                             ('bag', BaggingClassifier())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'final_model.sav'\n",
    "pickle.dump(vote, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
